jdbc-default {
	schema = "cos"
}
akka {
	loglevel = ERROR
	log-dead-letters-during-shutdown = on
	log-dead-letters = on
	actor {
		serialize-messages = off
		debug {
			receive = on // log all messages sent to an actor if that actors receive method is a LoggingReceive
			autoreceive = on // log all special messages like Kill, PoisoffPill etc sent to all actors
			lifecycle = on // log all actor lifecycle events of all actors
			fsm = off // enable logging of all events, transitioffs and timers of FSM Actors that extend LoggingFSM
			event-stream = on // enable logging of subscriptions (subscribe/unsubscribe) on the ActorSystem.eventStream
		}
		serializers {
			proto = "akka.remote.serialization.ProtobufSerializer"
		}
		serialization-bindings {
			# state is serialized using protobuf
			"scalapb.GeneratedMessage" = proto
			"com.google.protobuf.Message" = proto
		}

		# This will stop the guardian actor in case of any exception which will therefore
		# shutdown the whole actor system
		guardian-supervisor-strategy = "akka.actor.StoppingSupervisorStrategy"
	}

	persistence {
		# akka persistence jdbc
		journal.plugin = "jdbc-journal"
		snapshot-store.plugin = "jdbc-snapshot-store"
	}

	coordinated-shutdown {
		terminate-actor-system = off
		exit-jvm = off
		run-by-actor-system-terminate = off
		run-by-jvm-shutdown-hook = off
	}

	projection {
		slick {
			profile = "slick.jdbc.PostgresProfile$"
			db {
				connectionPool = disabled
				driver = "org.postgresql.Driver"
				user = ""
				password = ""
				serverName = ""
				databaseName = ""
				url = ""
			}
			offset-store {
				schema = ${jdbc-default.schema}
				table = "read_side_offsets"
				use-lowercase-schema = true
			}
		}
		restart-backoff {
			min-backoff = 3s
			max-backoff = 30s
			random-factor = 0.2
			max-restarts = -1
		}
		recovery-strategy {
			strategy = fail
			retries = 5
			retry-delay = 1 s
		}
	}
}


# general slick configuration
write-side-slick {
	profile = "slick.jdbc.PostgresProfile$"
	db {
		connectionPool = disabled
		driver = "org.postgresql.Driver"
		user = ""
		password = ""
		serverName = ""
		databaseName = ""
		url = ""
	}
}

jdbc-journal {
	tables {
		# Only used in pre 5.0.0 for backward-compatibility
		# ref: https://github.com/akka/akka-persistence-jdbc/blob/v5.0.0/core/src/main/resources/reference.conf
		legacy_journal {
			tableName = "journal"
			schemaName = ${jdbc-default.schema}
			columnNames {
				ordering = "ordering"
				deleted = "deleted"
				persistenceId = "persistence_id"
				sequenceNumber = "sequence_number"
				created = "created"
				tags = "tags"
				message = "message"
			}
		}

		# this is the new going forward
		# ref: https://github.com/akka/akka-persistence-jdbc/blob/v5.0.0/core/src/main/resources/reference.conf
		event_journal {
			tableName = "event_journal"
			schemaName = ${jdbc-default.schema}
			columnNames {
				ordering = "ordering"
				deleted = "deleted"
				persistenceId = "persistence_id"
				sequenceNumber = "sequence_number"
				writer = "writer"
				writeTimestamp = "write_timestamp"
				adapterManifest = "adapter_manifest"
				eventPayload = "event_payload"
				eventSerId = "event_ser_id"
				eventSerManifest = "event_ser_manifest"
				metaPayload = "meta_payload"
				metaSerId = "meta_ser_id"
				metaSerManifest = "meta_ser_manifest"
			}
		}

		event_tag {
			tableName = "event_tag"
			schemaName = ${jdbc-default.schema}
			columnNames {
				eventId = "event_id"
				tag = "tag"
			}
		}
	}
	tagSeparator = ","
	bufferSize = 1000
	batchSize = 400
	replayBatchSize = 400
	parallelism = 8
	logicalDelete = true
	dao = "akka.persistence.jdbc.journal.dao.DefaultJournalDao"
	slick = ${write-side-slick}
}

# the akka-persistence-query provider in use
jdbc-read-journal {
	# New events are retrieved (polled) with this interval.
	refresh-interval = "1s"
	# How many events to fetch in one query (replay) and keep buffered until they
	# are delivered downstreams.
	max-buffer-size = "500"
	tables {
		legacy_journal = ${jdbc-journal.tables.legacy_journal}
		event_journal = ${jdbc-journal.tables.event_journal}
		event_tag = ${jdbc-journal.tables.event_tag}
	}

	tagSeparator = ","
	# if true, queries will include logically deleted events
	# should not be configured directly, but through property akka-persistence-jdbc.logicalDelete.enable
	# in order to keep consistent behavior over write/read sides
	includeLogicallyDeleted = true

	# Settings for determining if ids (ordering column) in the journal are out of sequence.
	journal-sequence-retrieval {
		# The maximum number of ids that will be retrieved in each batch
		batch-size = 10000
		# In case a number in the sequence is missing, this is the ammount of retries that will be done to see
		# if the number is still found. Note that the time after which a number in the sequence is assumed missing is
		# equal to maxTries * queryDelay
		# (maxTries may not be zero)
		max-tries = 10
		# How often the actor will query for new data
		query-delay = 1 second
		# The maximum backoff time before trying to query again in case of database failures
		max-backoff-query-delay = 1 minute
		# The ask timeout to use when querying the journal sequence actor, the actor should normally repond very quickly,
		# since it always replies with its current internal state
		ask-timeout = 1 second
	}

	dao = "akka.persistence.jdbc.query.dao.DefaultReadJournalDao"
	slick = ${write-side-slick}
}

# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
	tables {
		# Only used in pre 5.0.0 for backward-compatibility
		# ref: https://github.com/akka/akka-persistence-jdbc/blob/v5.0.0/core/src/main/resources/reference.conf
		legacy_snapshot {
			tableName = "snapshot"
			schemaName = ${jdbc-default.schema}

			columnNames {
				persistenceId = "persistence_id"
				sequenceNumber = "sequence_number"
				created = "created"
				snapshot = "snapshot"
			}
		}

		# This is the new configuration going forward
		snapshot {
			tableName = "state_snapshot"
			schemaName = ${jdbc-default.schema}
			columnNames {
				persistenceId = "persistence_id"
				sequenceNumber = "sequence_number"
				created = "created"

				snapshotPayload = "snapshot_payload"
				snapshotSerId = "snapshot_ser_id"
				snapshotSerManifest = "snapshot_ser_manifest"

				metaPayload = "meta_payload"
				metaSerId = "meta_ser_id"
				metaSerManifest = "meta_ser_manifest"
			}
		}
	}
	dao = "akka.persistence.jdbc.snapshot.dao.DefaultSnapshotDao"

	slick = ${write-side-slick}
}
