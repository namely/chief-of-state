include "lagompb.conf"
play {
	modules.enabled += "com.namely.protobuf.chief_of_state.v1.AkkaGrpcClientModule"
	application {
		loader = com.namely.chiefofstate.ApplicationLoader
	}
	http {
		secret.key = "ahshrefhefjhefeboefvfvofefevelvenv"
		secret.key = ${?APPLICATION_SECRET}
	}
	server {
		provider = "play.core.server.AkkaHttpServerProvider"
		akka {
			http2 {
				enabled = true
			}
		}
		pidfile {
			path = /dev/null
		}
		http {
			# The default address is all address in case the environment variable PLAY_HTTP_ADDRESS and
			# properties file entry http.address are not found
			address = "0.0.0.0"
			address = ${?COS_ADDRESS}

			# The default port will be 9000 in case the environment variable PLAY_HTTP_PORT and properties
			# entry http.port are not found
			port = 9000
			port = ${?COS_PORT}

			# The idle timeout for an open connection after which it will be closed
			# Set to null or "infinite" to disable the timeout, but notice that this
			# is not encouraged since timeout are important mechanisms to protect your
			# servers from malicious attacks or programming mistakes.
			idleTimeout = 75 seconds
		}
	}
}

db {
	default {
		driver = "org.postgresql.Driver"
		username = "postgres"
		password = "changeme"
		username = ${?COS_POSTGRES_USER}
		password = ${?COS_POSTGRES_PASSWORD}
		host = "localhost"
		host = ${?COS_POSTGRES_HOST}
		port = "5432"
		port = ${?COS_POSTGRES_PORT}
		database = "postgres"
		database = ${?COS_POSTGRES_DB}
		schema = "public"
		schema = ${?COS_POSTGRES_SCHEMA}
		url = "jdbc:postgresql://"${db.default.host}":"${db.default.port}"/"${db.default.database}"?currentSchema="${db.default.schema}
	}
}

lagom {

	cluster {
		# exit jvm on actor system termination
		# this will allow Kubernetes to restart the pod
		exit-jvm-when-system-terminated = on
		bootstrap {
			enabled = on
		}
	}

	persistence {
		jdbc {
			create-tables.auto = false
			create-tables.auto = ${?COS_STORES_AUTO_CREATE}
		}
	}
}

akka {

	grpc {
		client {
			"chief_of_state.v1.WriteSideHandlerService" {
				# Host to use if service-discovery-mechanism is set to static or grpc-dns
				host = ${WRITE_SIDE_HANDLER_SERVICE_HOST}

				# port to use if service-discovery-mechism is static or service discovery does not return a port
				port = ${WRITE_SIDE_HANDLER_SERVICE_PORT}

				service-discovery {
					mechanism = "static"
					# Service name to use if a service-discovery.mechanism other than static or grpc-dns
					service-name = ""
					# See https://doc.akka.io/docs/akka-management/current/discovery/index.html for meanings for each mechanism
					# if blank then not passed to the lookup
					port-name = ""
					protocol = ""

					# timeout for service discovery resolving
					resolve-timeout = 1s
				}

				# pick_first or round_robin
				grpc-load-balancing = ""

				deadline = infinite
				override-authority = ""
				user-agent = ""
				use-tls = false

				creation {
					# How many times to retry client creation before giving up
					attempts = 1000

					# How long to wait between client creation attempts
					delay = 400ms
				}

				connection-attempts = -1
			}
			"chief_of_state.v1.ReadSideHandlerService" {
				service-discovery {
					mechanism = "static"
					# Service name to use if a service-discovery.mechanism other than static or grpc-dns
					service-name = ""
					# See https://doc.akka.io/docs/akka-management/current/discovery/index.html for meanings for each mechanism
					# if blank then not passed to the lookup
					port-name = ""
					protocol = ""

					# timeout for service discovery resolving
					resolve-timeout = 1s
				}

				# pick_first or round_robin
				grpc-load-balancing = ""

				deadline = infinite
				override-authority = ""
				user-agent = ""
				use-tls = false

				creation {
					# How many times to retry client creation before giving up
					attempts = 1000

					# How long to wait between client creation attempts
					delay = 400ms
				}

				connection-attempts = -1
			}
		}
	}

	projection {
		slick {
			# The Slick profile to use
			# set to one of: slick.jdbc.DerbyProfile$, slick.jdbc.H2Profile$, slick.jdbc.HsqldbProfile$, slick.jdbc.MySQLProfile$,
			#                slick.jdbc.PostgresProfile$, slick.jdbc.SQLiteProfile$, slick.jdbc.OracleProfile$
			#profile = <fill this with your profile of choice>
			profile = "slick.jdbc.PostgresProfile$"
			# add here your Slick db settings
			db {
				driver = "org.postgresql.Driver"
				user = "postgres"
				user = ${?COS_READ_SIDE_OFFSET_DB_USER}
				password = "changeme"
				password = ${?COS_READ_SIDE_OFFSET_DB_PASSWORD}
				serverName = "localhost"
				serverName = ${?COS_READ_SIDE_OFFSET_DB_HOST}
				portNumber = 5432
				portNumber = ${?COS_READ_SIDE_OFFSET_DB_PORT}
				databaseName = "postgres"
				databaseName = ${?COS_READ_SIDE_OFFSET_DB}
				url = "jdbc:postgresql://"${akka.projection.slick.db.serverName}":"${akka.projection.slick.db.portNumber}"/"${akka.projection.slick.db.databaseName}"?currentSchema="${akka.projection.slick.offset-store.schema}
				connectionPool = "HikariCP"
				keepAliveConnection = true
			}

			offset-store {
				# set this to your database schema if applicable, empty by default
				schema = "public"
				schema = ${?COS_READ_SIDE_OFFSET_DB_SCHEMA}
				# the database table name for the offset store
				table = "AKKA_PROJECTION_OFFSET_STORE"
				table = ${?COS_READ_SIDE_OFFSET_STORE_TABLE}
			}
		}
		restart-backoff {
			min-backoff = 3s
			max-backoff = 30s
			random-factor = 0.2

			# -1 will not cap the amount of restarts
			# 0 will disable restarts
			max-restarts = -1
		}
	}

	http {
		server {
			preview {
				enable-http2 = on
			}
		}
	}
}

lagompb {
	service-name = "chiefofstate"
	service-name = ${?COS_SERVICE_NAME}

	# Protocol buffers package name to allow lagompb to
	# automatically build a descriptor registry
	protos-package = "com.namely.protobuf"

	# Ask timeout is required to
	# send commands to the aggregate root and receive response
	# the unit value is in second
	# This is is not a gRPC timeout.
	# This is timeout is required by the entity receiving a command to respond back to the caller.
	ask-timeout = 5
	ask-timeout = ${?COS_COMMAND_HANDLER_TIMEOUT}

	snapshot-criteria {
		# number of events to batch persist
		frequency = 100
		frequency = ${?COS_EVENTS_BATCH_THRESHOLD}
		# number of snapshots to retain
		retention = 2
		retention = ${?COS_NUM_SNAPSHOTS_TO_RETAIN}
		# this feature allow to clean the journal history
		# Event deletion is triggered after saving a new snapshot. Old events would be deleted prior to old snapshots being deleted
		# reference: https://doc.akka.io/docs/akka/current/typed/persistence-snapshot.html#event-deletion
		delete-events-on-snapshot = false
		delete-events-on-snapshot = ${?COS_JOURNAL_LOGICAL_DELETION}
	}

	events {
		# the events tag name. It is recommended to use the service name
		# because the event tag name must be unique and cannot be changed once the application has handled
		# an aggregate event.
		# Reference: https://www.lagomframework.com/documentation/latest/scala/ReadSide.html#Refactoring-Consideration
		tagname: "chiefofstate"
	}

	projection {
		create-tables.auto = false
		create-tables.auto = ${?COS_STORES_AUTO_CREATE}
	}

}

chief-of-state {

	# Helps switch on/off the readSide model
	read-model {
		# helps turn on/off the readside processor
		enabled = false
		enabled = ${?COS_READ_SIDE_ENABLED}
	}

	# define settings for the handler services
	handlers-settings {
		# Whether to allow validation of the state and events FQNs
		# if set to true, validation is done, by default it is false.
		enable-proto-validation = false
		enable-proto-validation = ${?HANDLER_SERVICE_ENABLE_PROTO_VALIDATION}
		# define the fully qualified type url  of the state proto
		# example: namely.org_units.OrgUnit
		states-proto = ""
		states-proto = ${?HANDLER_SERVICE_STATES_PROTOS}
		# list if the fully qualified type url  of the events handled
		# example: "namely.org_units.OrgUnitTypeCreated", "namely.org_units.OrgUnitTypeUpdated"
		events-protos = ""
		events-protos = ${?HANDLER_SERVICE_EVENTS_PROTOS}
		# custom dispatcher for command  hander
		# Since the command handler is blocking call it is recommended
		# to use a custom dispatcher to handle this type of calls.
		# The thread pool size should be fine tuned depending on the workload you’re expecting to run on this dispatcher.
		# https://doc.akka.io/docs/akka/current/typed/dispatchers.html#solution-dedicated-dispatcher-for-blocking-operations
		# https://github.com/akka/akka/blob/master/akka-actor/src/main/resources/reference.conf
		writeside-dispatcher {
			type = Dispatcher
			executor = "thread-pool-executor"
			thread-pool-executor {
				# Keep alive time for threads
				keep-alive-time = 60s

				# Define a fixed thread pool size with this property. The corePoolSize
				# and the maximumPoolSize of the ThreadPoolExecutor will be set to this
				# value, if it is defined. Then the other pool-size properties will not
				# be used.
				#
				# Valid values are: `off` or a positive integer.
				fixed-pool-size = off

				# Min number of threads to cap factor-based corePoolSize number to
				core-pool-size-min = 8

				# The core-pool-size-factor is used to determine corePoolSize of the
				# ThreadPoolExecutor using the following formula:
				# ceil(available processors * factor).
				# Resulting size is then bounded by the core-pool-size-min and
				# core-pool-size-max values.
				core-pool-size-factor = 3.0

				# Max number of threads to cap factor-based corePoolSize number to
				core-pool-size-max = 64

				# Minimum number of threads to cap factor-based maximumPoolSize number to
				max-pool-size-min = 8

				# The max-pool-size-factor is used to determine maximumPoolSize of the
				# ThreadPoolExecutor using the following formula:
				# ceil(available processors * factor)
				# The maximumPoolSize will not be less than corePoolSize.
				# It is only used if using a bounded task queue.
				max-pool-size-factor = 3.0

				# Max number of threads to cap factor-based maximumPoolSize number to
				max-pool-size-max = 64

				# Specifies the bounded capacity of the task queue (< 1 == unbounded)
				task-queue-size = -1

				# Specifies which type of task queue will be used, can be "array" or
				# "linked" (default)
				task-queue-type = "linked"

				# Allow core threads to time out
				allow-core-timeout = on
			}
			# Throughput defines the maximum number of messages to be
			# processed per actor before the thread jumps to the next actor.
			# Set to 1 for as fair as possible.
			throughput = 1
		}
		# custom dispatcher for read  hander
		# Since the read handler is blocking call it is recommended
		# to use a custom dispatcher to handle this type of calls.
		# The thread pool size should be fine tuned depending on the workload you’re expecting to run on this dispatcher.
		# https://doc.akka.io/docs/akka/current/typed/dispatchers.html#solution-dedicated-dispatcher-for-blocking-operations
		# https://github.com/akka/akka/blob/master/akka-actor/src/main/resources/reference.conf
		readside-dispatcher {
			type = Dispatcher
			executor = "thread-pool-executor"
			thread-pool-executor {
				# Keep alive time for threads
				keep-alive-time = 60s

				# Define a fixed thread pool size with this property. The corePoolSize
				# and the maximumPoolSize of the ThreadPoolExecutor will be set to this
				# value, if it is defined. Then the other pool-size properties will not
				# be used.
				#
				# Valid values are: `off` or a positive integer.
				fixed-pool-size = off

				# Min number of threads to cap factor-based corePoolSize number to
				core-pool-size-min = 8

				# The core-pool-size-factor is used to determine corePoolSize of the
				# ThreadPoolExecutor using the following formula:
				# ceil(available processors * factor).
				# Resulting size is then bounded by the core-pool-size-min and
				# core-pool-size-max values.
				core-pool-size-factor = 3.0

				# Max number of threads to cap factor-based corePoolSize number to
				core-pool-size-max = 64

				# Minimum number of threads to cap factor-based maximumPoolSize number to
				max-pool-size-min = 8

				# The max-pool-size-factor is used to determine maximumPoolSize of the
				# ThreadPoolExecutor using the following formula:
				# ceil(available processors * factor)
				# The maximumPoolSize will not be less than corePoolSize.
				# It is only used if using a bounded task queue.
				max-pool-size-factor = 3.0

				# Max number of threads to cap factor-based maximumPoolSize number to
				max-pool-size-max = 64

				# Specifies the bounded capacity of the task queue (< 1 == unbounded)
				task-queue-size = -1

				# Specifies which type of task queue will be used, can be "array" or
				# "linked" (default)
				task-queue-type = "linked"

				# Allow core threads to time out
				allow-core-timeout = on
			}
			# Throughput defines the maximum number of messages to be
			# processed per actor before the thread jumps to the next actor.
			# Set to 1 for as fair as possible.
			throughput = 1
		}
	}

	send-command {
		# csv of gRPC headers to propagate to write-side handler
		propagated-headers = ""
		propagated-headers = ${?COS_WRITE_PROPAGATED_HEADERS}
	}

	encryption {
		# lagom-pb ProtoEncryption used for lagom-pb event/snapshot adapters
		# must implement io.superflat.lagompb.encryption.ProtoEncryption
		# or leave as empty string if no encryption desired
		encryption-class = ""
		encryption-class = ${?COS_ENCRYPTION_CLASS}
	}

	plugin-settings {
		enable-plugins = ""
		enable-plugins = ${?COS_ENABLE_PLUGINS}
	}
}

kamon {
	environment {
		service = ${lagompb.service-name}
	}

	trace {
		tick-interval = 1 millisecond
		sampler = always
	}

	propagation.http.default.tags.mappings {
		request-id = "x-request-id"
	}

	jaeger {
		host = "localhost"
		host = ${?JAEGER_HOST}
		port = 14268
		port = ${?JAEGER_PORT}
		http-url = ${kamon.jaeger.protocol}"://"${kamon.jaeger.host}":"${kamon.jaeger.port}"/api/traces"
		http-url = ${?JAEGER_URL}
	}
	zipkin {
		host = "localhost"
		host = ${?ZIPKIN_HOST}
		port = 9411
		port = ${?ZIPKIN_PORT}
		url = ${kamon.zipkin.protocol}"://"${kamon.zipkin.host}":"${kamon.zipkin.port}"/api/v2/spans"
		url = ${?ZIPKIN_URL}
	}
	modules {
		jaeger {
			enabled = false
			enabled = ${?JAEGER_ENABLED}
		}
		zipkin-reporter {
			enabled = false
			enabled = ${?ZIPKIN_ENABLED}
		}
	}
}
